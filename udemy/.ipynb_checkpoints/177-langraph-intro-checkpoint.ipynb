{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2907e96e-faf8-4441-bdc8-c3ae1b77457a",
   "metadata": {},
   "source": [
    "# Intro to LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3998720-f7c8-4707-84ce-39f51b3d0913",
   "metadata": {},
   "source": [
    "## What is LangGraph?\n",
    "* LangGraph is a library for building stateful, multi-actor applications with LLMs, built on to of (and intended to be used with) LangChain.\n",
    "* LangGraph extends LCEL with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cycling manner.\n",
    "* The main use of LanGraph is for adding cycles to a LLM application. Cycles are important for agent-like behaviors, where you call an LLM in a loop, asking it what action to take next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e8ca4-c20f-4cf1-b912-59e342648fa6",
   "metadata": {},
   "source": [
    "## Why LangGraph?\n",
    "* LangGraph was added with the version v0.1 of LangChain in February 2024.\n",
    "* One of the big value props of LangChain is the ability to easily create custom chains. However, until v0.1 LangChain lacked a method for easily introducing cycles into these chains.\n",
    "* And having and easy ways to introduce cycles was important, since one of the common patterns we see when people are creating more complex LLM applications is the introduction of cycles into the runtime. These cycles often use the LLM to reason about what to do next in the cycle. This can essentially be thought of as running an LLM in a for-loop, and these types of systems is what are called LLM Agents , AI Agents or AI Assistants.\n",
    "* LangGraph is module built on top of LangChain to better enable creation of **cyclical graphs**, often needed for agent runtimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f67f1-0948-43aa-b161-ae5c15cfe852",
   "metadata": {},
   "source": [
    "## The need for the Agentic Behavior\n",
    "* Let's see the need for the Agentic Behavior considering what happens in a typical RAG application, a call to a retriever is made that returns some documents. These documents are then passed to an LLM to generate a final answer.\n",
    "* While this is often effective, it breaks down in cases when the first retrieval step fails to return any useful results.\n",
    "* In this case, it's often ideal if **the LLM can reason that the results returned from the retriever are poor, and maybe issue a second (more refined) query to the retriever**, and use those results instead.\n",
    "* Essentially, **the Agentic Behavior allows running an LLM in a loop to help create applications that are more flexible** and thus can accomplish more vague use-cases that may not be predefined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173996f-4edb-4f09-a37f-9cb12df613e4",
   "metadata": {},
   "source": [
    "## The simplest agent\n",
    "The simplest agent is a loop that essentially has two steps:\n",
    "* Call the LLM to determine either\n",
    "    * (a) what actions to take, or\n",
    "    * (b) what response to give the user\n",
    "* Take given actions, and pass back to step 1.\n",
    "\n",
    "These steps are repeated until a final response is generated.\n",
    "\n",
    "This is essentially the loop that powers LangChain's AgentExecutor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97931ee0-3919-4def-a6ed-cf13546ae9da",
   "metadata": {},
   "source": [
    "## More control is needed\n",
    "Often times more control is needed: \n",
    "* You may want to always force an agent to call particular tool first.\n",
    "* You may want have more control over how tools are called.\n",
    "* You may want to have different prompts for the agent, depending on that state it is in.\n",
    "* Etc.\n",
    "\n",
    "When talking about the architecture of these more controlled flows, LangChain refer to them as \"state machine\" architecture (to learn more about this, see the previous notebook called 174-langchain-vs-openai-agents.ipynb).\n",
    "\n",
    "LangGraph allows to create these state machines by specifying them as graphs.\n",
    "\n",
    "After we define one graph with LangGraph, we can compile it into a runnable. This runnable exposes all the same method as LangChain runnables (.invoke, .stream, .astream_log, etc) allowing it to be called in the same manner as a chain.\n",
    "\n",
    "LangChain has recreated the AgentExecutor with LangGraph. This allows you to use existing LangChain agents and more easily modify the internals of the AgentExecutor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05984bdf-2a27-464b-94ed-d7d1e8623ecc",
   "metadata": {},
   "source": [
    "## The future of LangGraph\n",
    "Some of the things the LangChain team is looking to implement in the near future:\n",
    "\n",
    "* More advanced agent runtimes from academia (LLM Compiler, plan-and-solve, etc).\n",
    "* Stateful tools (allowing tools to modify some state).\n",
    "* More controlled human-in-the-loop workflows.\n",
    "* **Multi-agent workflows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25fcc7-8bbb-4796-8704-38b17a4d03b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
