{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bf54eb-02ec-49d0-8fa0-a7135eeef1a1",
   "metadata": {},
   "source": [
    "# Closed-Source Agents vs. Open-Source Agents: OpenAI vs LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966a91a-0881-4d4c-9441-86c4a41b4279",
   "metadata": {},
   "source": [
    "## OpenAI's closed Agents\n",
    "* On Nov 2023, OpenAI released the new Assistants API and GPTs. With them, OpenAI is betting on a agent-like closed cognitive architecture.\n",
    "* OpenAI's GPTs can be customized with:\n",
    "    * instructions.\n",
    "    * knowledge.\n",
    "    * functions.\n",
    "* OpenAI's GPTs seem to be a second attempt at an app store of sorts after the failed Plugins, which did not find product-market fit.\n",
    "* OpenAI's Assistants API allows developers to build Assistants with:\n",
    "    * storage of previous messages.\n",
    "    * uploading of files.\n",
    "    * access to built-in tools.\n",
    "    * control other tools through function calling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ee4d6-0dc8-4c3b-b58f-ba151b73483f",
   "metadata": {},
   "source": [
    "## Cognitive Architectures\n",
    "* OpenAI's Assistant API and GPTs both represent a similar type of cognitive architecture: agents.\n",
    "* The cognitive architecture describes the orchestration of an LLM application.\n",
    "* LangChain has identified 5 types of cognitive architectures for LLM apps:\n",
    "    * A single LLM call.\n",
    "    * A chain of LLM calls.\n",
    "    * Using LLM as a router to choose which tool to use.\n",
    "    * Using LLMs to route between steps (State machines).\n",
    "    * Using LLM to wholly determine the transition options (Agents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a8535-7708-4c44-a891-a927c85d74cc",
   "metadata": {},
   "source": [
    "## The Agent Cognitive Architecture: What do AI Agent Applications look like?\n",
    "* Given user input, a loop will be entered.\n",
    "* An LLM is then called, resulting in:\n",
    "    * either a response to the user\n",
    "    * or action(s) to be taken\n",
    "* If it is determined that a respose is required, then that is passed to the user and the cycle is finished.\n",
    "* If it is determined that an action is required, that action is then taken and an observation (action result) is made. That action and the corresponding observation are added back to the prompt and the loop resets (the LLM is called again): this is called \"agent scratchpad\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4d413-3c24-4ab6-9340-b79348091f5f",
   "metadata": {},
   "source": [
    "## The Agent Architecture is still not reliable for serious applications, but the OpenAI move tells they can be soon.\n",
    "* OpenAI is betting that over time the issues that plague agents will go away.\n",
    "* And they are the best positioned out of anyone to make agents work, since they control de underlying LLM Foundation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24124d5a-8c5e-4d9d-972a-ab22e9b4ab75",
   "metadata": {},
   "source": [
    "## Nearly all current agents differ in two key aspects\n",
    "* Many do not fit into the agent cognitive architecture, they are instead complex chains more similar to State Machines. Examples of this are GPT-Researcher or Sweep.dev.\n",
    "* Applications that use agent architecture differ from GPTs on how context is provided to the agent.\n",
    "    * Context can either be provided via pulling or pushing.\n",
    "    * When context pulling is used, the agent decides what context it needs, and then asks for it. This generally happens via a tool.\n",
    "    * GPTs and the Assistant API largely empower apps with context pulling. \n",
    "    * **In most performant and reliable agents, however, context is provided via pushing**. It gives developers more control.\n",
    "    * When context pushing is used, it is encoded in the logic of the app that a particular context should be fetched and pushed into the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4514c-ca95-41c7-a05e-01e23e9a90ed",
   "metadata": {},
   "source": [
    "## Closed vs Open Agents\n",
    "* As developers, we do not know what is going on under the hood when we use OpenAI's GPTs and the Assistants API. They have closed-source agent architecture:\n",
    "    * what is being done to manage the context of the chat history?\n",
    "    * what is being done for retrieval?\n",
    "    * Etc. As they add more functionality, it will become more and more of a black box.\n",
    "* LangChain's open-source agent architecture gives developers more control. This has several advantages:\n",
    "    * Today it is still very difficult to make agents actually function, so the more control you have over architecture the more you can improve them.\n",
    "    * The value of GenAI apps is closely tied to the performance of the architecture. The architecture is the product, so the more you control it the more differencial value you can offer.\n",
    "    * When it comes the time to increase performace and run at scale, you need to customize the architecture to your app and your user case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e0bec-1bb3-44e0-8047-b93c061a4794",
   "metadata": {},
   "source": [
    "## LangChain's Open Agents\n",
    "* LangChain is betting on an open architecture to build agents. This gives developers more control to configure and customize agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc40b1-8fb3-4661-9a3c-69cda095f4f1",
   "metadata": {},
   "source": [
    "## LangChain's OpenGPTs\n",
    "* LangChain has released the project [OpenGPTs](https://github.com/langchain-ai/opengpts?ref=blog.langchain.dev) as an attempt to recreate the same experience as the OpenAI's Assistants API and GPTs. OpenGPTs is open sourced and configurable with different model providers, and the retrieval method can be easily modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0648a-d9ed-44bd-a537-fb1e61f987fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
