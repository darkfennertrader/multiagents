{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1186f437-af5b-4c11-9151-48f5fc85ec64",
   "metadata": {},
   "source": [
    "# Agents with LangChain: Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c5a3f-01c8-4118-a7fc-a2017d4b7ea8",
   "metadata": {},
   "source": [
    "## Goal of an AI Agent\n",
    "* To use an LLM Model as a reasoning engine to determine which actions to take and in which order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf58478-7cba-4c85-98b8-7ff4020f1d4a",
   "metadata": {},
   "source": [
    "## Key concepts\n",
    "* **AgentAction**: the action an agent must take.\n",
    "    * Tool: tool to be invoked.\n",
    "    * Tool_input: the input to that tool. \n",
    "* **AgentFinish**: the final result from an agent.\n",
    "* **Intermediate Steps**: previous agent actions and outputs from the current agent run.\n",
    "* **Agent inputs**: inputs to an agent.\n",
    "* **Agent outputs**: next action to take or the final response.\n",
    "* **AgentExecutor**: the runtime for an agent. This is what:\n",
    "    * calls the agent,\n",
    "    * executes the actions it chooses,\n",
    "    * passes the action outputs back to the agent,\n",
    "    * and repeats.\n",
    "* **Tools**: functions that an agent can invoke.\n",
    "* **Toolkits**: groups of around 3-5 tools needed to accomplish specific objectives.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadb5da-b23d-4a80-ba1d-abc8c0634ea3",
   "metadata": {},
   "source": [
    "## Agent Types\n",
    "* Classified by:\n",
    "    * Intended model type: chat model or LLM.\n",
    "    * Supports chat history or not.\n",
    "    * Supports multi-input tools or not.\n",
    "    * Supports parallel function calling or not.\n",
    "    * Required model params.\n",
    "    * When to use it.\n",
    "* Agent types:\n",
    "    * **General Tool Calling Agent**: If you are using a tool-calling model.\n",
    "    * **OpenAI Tool Calling Agent**: [Legacy] If you are using a recent OpenAI model (1106 onwards). Generic Tool Calling agent recommended instead.\n",
    "    * **OpenAI Function Calling Agent**. [Legacy] If you are using an OpenAI model, or an open-source model that has been finetuned for function calling and exposes the same functions parameters as OpenAI. Generic Tool Calling agent recommended instead.\n",
    "    * **XXL Agent**: If you are using Anthropic models, or other models good at XML.\n",
    "    * **Structured Chat Agent**: If you need to support tools with multiple inputs.\n",
    "    * **JSON Chat Agent**: If you are using a model good at JSON.\n",
    "    * **ReAct Agent**: If you are using a simple model.\n",
    "    * **Self-ask with search Agent**: If you are using a simple model and only have one search tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185c7aa-cd9d-43a9-b30c-8b2d917ba7d3",
   "metadata": {},
   "source": [
    "## Agent Tools\n",
    "* Agents are only as good as the tools they have.\n",
    "* [Quickstart on Tools.](https://python.langchain.com/docs/modules/tools/)\n",
    "* [List of LangChain's Built-in Tools.](https://python.langchain.com/docs/integrations/tools/)\n",
    "* [Quickstart on Toolkits.](https://python.langchain.com/docs/modules/tools/toolkits/)\n",
    "* [List of LangChain's Built-in Toolkits.](https://python.langchain.com/docs/integrations/toolkits/)\n",
    "* [How to build Custom Tools.](https://python.langchain.com/docs/modules/tools/custom_tools/)\n",
    "* [How to use LangChain's Tools as OpenAI's Functions.](https://python.langchain.com/docs/modules/tools/tools_as_openai_functions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e58f75-6577-4b9f-acb1-075c2342297e",
   "metadata": {},
   "source": [
    "# LangChain Agents Quickstart\n",
    "* We will build an agent that uses 2 tools:\n",
    "    * One tool to search online.\n",
    "    * Another tool to answer questions from private data (RAG). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265779f-b3c3-4114-859f-7acf6f114406",
   "metadata": {},
   "source": [
    "## Setup: .env file and LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb1589-b14f-4249-85b1-1f25425eba74",
   "metadata": {},
   "source": [
    "#### Recommended: create new virtualenv\n",
    "* pyenv virtualenv 3.11.4 your_venv_name\n",
    "* pyenv activate your_venv_name\n",
    "* pip install jupyterlab\n",
    "* jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b06ed78-a8ad-4dbe-803e-403d76934be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ba3c1-6020-4d53-a53a-8e87dedef237",
   "metadata": {},
   "source": [
    "#### .env File\n",
    "Remember to include:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68440634-785d-49e5-9e4a-b52e2e7137a9",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **AGENTSquickstart**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5caf84-e3e8-4c66-8929-fc376a832cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9824af5-54c0-4eea-bfd8-c3821863eded",
   "metadata": {},
   "source": [
    "## Tool Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ffe94a-d47d-4d78-b6c0-1cf572c9164c",
   "metadata": {},
   "source": [
    "#### Prepare the Online Search Tool: Tavily\n",
    "* Get a free Tavily API key:\n",
    "    * Select the free Tavily plan [here.](https://tavily.com/#pricing)\n",
    "    * Log in to Tavily.\n",
    "    * Copy the API Key.\n",
    "    * Paste the API Key in the .env file:\n",
    "        * TAVILY_API_KEY=your_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a89874-f707-4c3f-9cfe-46fa23982060",
   "metadata": {},
   "source": [
    "* Confirm that you can now access Tavily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a17661-7d4b-4b54-967a-4b12845a11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11813307-9ed9-414b-bc3b-e78bd528f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4c226-eb0b-4da5-8bc2-9d3ea38dd689",
   "metadata": {},
   "source": [
    "* Define the Search Tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "291492ee-2231-4605-968f-3735afd98d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5eca74-5a55-42b6-9cd7-2ac1e07e5011",
   "metadata": {},
   "source": [
    "* Confirm that you can now access the Search Tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd67933b-286c-45ea-9fb9-3b5ed61fe3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.bbc.co.uk/sport/football/68869328',\n",
       "  'content': \"Jude Bellingham scores late as Real Madrid beat Barcelona to move 11 points clear at the top of La Liga after an enthralling El Clasico. ... Match ends, Real Madrid 3, Barcelona 2. 90'+5' Full ...\"},\n",
       " {'url': 'https://www.sportingnews.com/us/soccer/news/real-madrid-vs-barcelona-live-score-result-updates-stats-lineups-el-clasico/552e9e838f75308ba4ecc07c',\n",
       "  'content': \"Jude Bellingham's stoppage-time winner gave Real Madrid a thrilling 3-2 victory over bitter rivals Barcelona in El Clasico and all-but secured LaLiga glory for Carlo Ancelotti's side.\"},\n",
       " {'url': 'https://www.cbssports.com/soccer/news/el-clasico-score-jude-bellinghams-late-winning-goal-lifts-real-madrid-past-barcelona/live/',\n",
       "  'content': 'Real Madrid came back from behind twice to beat Barcelona 3-2 on Sunday, giving them an 11-point gap atop the table as they inch closer to their first La Liga title in two years.'},\n",
       " {'url': 'https://www.bbc.com/sport/live/football/68837905',\n",
       "  'content': \"Follow live text commentary as Real Madrid host Barcelona in the final 'El Clasico' of the season.\"},\n",
       " {'url': 'https://theathletic.com/live-blogs/real-madrid-barcelona-live-updates-el-clasico-score-result/FEVfykoVvrj2/',\n",
       "  'content': \"Real Madrid have now won four straight meetings with Barcelona in all competitions, including three this season. It's just the fifth time that Madrid have won at least three Clasicos in a single ...\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"What was the score of the Real Madrid - Barcelona match played yesterday?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541cf19c-40f4-49ac-8e76-1c9607223e95",
   "metadata": {},
   "source": [
    "* See that LangSmith has started tracking operations: [https://smith.langchain.com/](https://smith.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ecf5c-a20b-4e10-8cf6-ad4be2f22880",
   "metadata": {},
   "source": [
    "#### Prepare the RAG tool\n",
    "* RAG tool loading data from a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1c2516e-3249-411c-9f99-284847cbe72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "257cda54-9b9d-41c0-bc0c-b41cf8d62eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35882e81-d418-41c2-95ab-25b4ae655fab",
   "metadata": {},
   "source": [
    "* Confirm that RAG works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "796d9ab5-2309-4c5c-afb0-e098df0dc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='import Clientfrom langsmith.evaluation import evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\":', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089accd-38dd-4382-8fcc-57c7ba962a4f",
   "metadata": {},
   "source": [
    "* Define the RAG tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65364345-faa1-49e4-95ce-9e8c87548a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5d5d360-c170-4dc8-8860-cc9efad67d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17c288-1028-41f1-bc74-98a09c594336",
   "metadata": {},
   "source": [
    "## Let's now add a custom tool\n",
    "* When we define a custom tool we need to use the @tool decorator. Learn more about this [here.](https://python.langchain.com/docs/modules/tools/custom_tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86726c03-a782-4845-b2b9-724a1e9b5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6eb75d95-c3cf-4aca-adbb-bdffb5ecda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length_tool(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c182a9-8d37-467c-a062-1fbc28003bd5",
   "metadata": {},
   "source": [
    "* Let's confirm that this new tool works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92198cc4-19bd-433d-8aef-7d9e7530162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length_tool.invoke(\"julio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda6619-b8dd-4208-8e59-36222d70ca51",
   "metadata": {},
   "source": [
    "## Create the list of tools that will be available for the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19ccc526-5305-4b84-be26-e03b8617b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, retriever_tool, get_word_length_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bc274-0446-4d93-82e6-e512bcfb3502",
   "metadata": {},
   "source": [
    "## Create the agent\n",
    "* We will create an **OpenAI Functions Agent** (see the different Agent Types in the above section)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cd0d8-7ef7-46ad-bbf8-06bc0d6268d2",
   "metadata": {},
   "source": [
    "#### Choose the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a3cae77-1a6a-44ff-8c89-8a54a5486b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe1a99-f489-4990-85ef-8dd7629d2df5",
   "metadata": {},
   "source": [
    "#### Define the Agent Prompt\n",
    "* The Agent Prompt will guide the agent.\n",
    "* For this example, we will use a pre-defined prompt from the LangSmith Prompt Hub. See the prompt definition [here.](https://smith.langchain.com/hub/hwchase17/openai-functions-agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e0c1c23-c8a6-4264-8ea7-4b363a598bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a11f1b0b-8bac-44d8-86c5-91e9da24f4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c917145-83b5-4329-bf24-a5ab251a8325",
   "metadata": {},
   "source": [
    "#### Initialize the agent\n",
    "* With the LLM, the prompt and the tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d380b7f-7319-485e-9290-42cbf3e03c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d398e-6de0-4178-a1e3-f9b8eda1e18d",
   "metadata": {},
   "source": [
    "* Given our input, the agent will decide what actions to take.\n",
    "* The agent will not execute those actions, that is done by the AgentExecutor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7071b5e-6129-4b54-9323-193120679a4b",
   "metadata": {},
   "source": [
    "#### Initialize the AgentExecutor\n",
    "* We combine the agent with the tools inside the AgentExecutor, which will repeatedly call the agent and execute tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d572feee-d935-40fb-8d18-e26cfe3a35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05722721-e9fb-4dcb-b844-239623a2a4e0",
   "metadata": {},
   "source": [
    "## We can now start using the agent\n",
    "* Keep in mind that this is a very basic agent that will not remember previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d77dea0-521e-4cc0-ac95-68f0b75ec56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! I'm an AI assistant here to help you with any questions or tasks you have. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! who are you?',\n",
       " 'output': \"Hello! I'm an AI assistant here to help you with any questions or tasks you have. How can I assist you today?\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi! who are you?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8f790-ea7a-4c49-8221-2f128600bb2b",
   "metadata": {},
   "source": [
    "* Let's now ask a question related with the RAG tool (remember that the RAG tool answers basic questions about LangSmith)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "174136b6-dffe-4cd8-8e9d-d546ba8f96c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'What is LangSmith in less than 20 words?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGetting started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install LangSmith‚ÄãWe offer Python and Typescript SDKs for all your LangSmith needs.PythonTypeScriptpip install -U langsmithyarn add langchain langsmithCreate an API key‚ÄãTo create an API key head to the setting pages. Then click Create API Key.Setup your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>Log your first trace‚ÄãWe provide multiple ways to log traces\n",
      "\n",
      "Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!FAQ‚ÄãHow do I migrate projects between organizations?‚ÄãCurrently we do not support project migration betwen organizations. While you can manually imitate this by\n",
      "\n",
      "team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?‚ÄãIf you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API keySetup your environmentLog your first traceCreate your first evaluationNext StepsAdditional ResourcesFAQHow do I migrate projects between organizations?Why aren't my runs aren't showing up in my project?My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications, enabling monitoring, evaluation, and quick deployment with confidence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'in less than 20 words, what is langsmith?',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM applications, enabling monitoring, evaluation, and quick deployment with confidence.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"in less than 20 words, what is langsmith?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b23f2-252b-4ae0-a6b1-5272e9a510ce",
   "metadata": {},
   "source": [
    "* See how this operation has been tracked in LangSmith: [https://smith.langchain.com/](https://smith.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22138f2-b20d-4557-b02b-ce39882831e5",
   "metadata": {},
   "source": [
    "* Let's now ask a question non related to LangSmith in order to trigger the Online Search tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "881d1204-05b4-4b7a-b825-1746b2a196af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'last goal scorer Real Madrid Barcelona soccer match yesterday'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://theathletic.com/live-blogs/real-madrid-barcelona-live-updates-el-clasico-score-result/FEVfykoVvrj2/', 'content': \"Barcelona thought they had gone 2-1 ahead when Yamal's near-post flick at a corner arrowed the ball towards goal. Lunin got across to shovel it out, but the impression watching ‚Äî and Barca's ...\"}, {'url': 'https://www.bbc.co.uk/sport/football/68869328', 'content': 'Jude Bellingham has scored 21 goals across all competitions this season. Jude Bellingham scored a late winner as Real Madrid beat Barcelona to move 11 points clear at the top of La Liga after an ...'}, {'url': 'https://www.sportingnews.com/us/soccer/news/real-madrid-vs-barcelona-live-score-result-updates-stats-lineups-el-clasico/552e9e838f75308ba4ecc07c', 'content': \"Jude Bellingham's stoppage-time winner gave Real Madrid a thrilling 3-2 victory over bitter rivals Barcelona in El Clasico and all-but secured LaLiga glory for Carlo Ancelotti's side.\"}, {'url': 'https://www.eurosport.com/football/la-liga/2023-2024/real-madrid-v-barcelona-la-liga-live_sto10108043/story.shtml', 'content': \"Real Madrid's English midfielder #5 Jude Bellingham celebrates scoring his team's third goal, with Real Madrid's Spanish forward #14 Joselu, during the Spanish league football match between Real ...\"}, {'url': 'https://www.cbssports.com/soccer/news/el-clasico-score-jude-bellinghams-late-winning-goal-lifts-real-madrid-past-barcelona/live/', 'content': 'Real Madrid came back from behind twice to beat Barcelona 3-2 on Sunday, giving them an 11-point gap atop the table as they inch closer to their first La Liga title in two years.'}]\u001b[0m\u001b[32;1m\u001b[1;3mJude Bellingham scored the last goal in the Real Madrid - Barcelona soccer match yesterday.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who scored the last goal in the Real Madrid - Barcelona soccer match yesterday?',\n",
       " 'output': 'Jude Bellingham scored the last goal in the Real Madrid - Barcelona soccer match yesterday.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Who scored the last goal in the Real Madrid - Barcelona soccer match yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41390e63-cc7d-47a5-9b7d-979f5a551d20",
   "metadata": {},
   "source": [
    "* See how this operation has been tracked in LangSmith: [https://smith.langchain.com/](https://smith.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa8d2b-e051-4297-9f6e-68412a5787fa",
   "metadata": {},
   "source": [
    "* Let's try now asking something related to the custom tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b161ed6-5e4a-4c00-826f-12e4fd55072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length_tool` with `{'word': 'AIAccelera'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m10\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"AIAccelera\" has 10 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many letters are in the word AIAccelera?',\n",
       " 'output': 'The word \"AIAccelera\" has 10 letters.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"How many letters are in the word AIAccelera?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cf07c-5f8e-4a71-927b-6ae2c82040f9",
   "metadata": {},
   "source": [
    "## Adding memory to the agent\n",
    "* Right now, our basic agent does not remember previous interactions. Technically, we say that our agent is \"stateless\".\n",
    "* If we want the agent to remember previous interactions, we could achieve it message by message, or automatically. For the sake of simplicity, let's first see how to do it message by message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deb45edd-225c-48fd-a20d-add73443cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Julio! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is julio',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Julio! How can I assist you today?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages \n",
    "# for chat_history because it is the first \n",
    "# message in the chat\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"hi! my name is julio\", \n",
    "        \"chat_history\": []\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da948013-f59a-4cd9-a93e-6e5f4ed96fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ce56ee5-4c02-4e2b-9091-1a3c3bab915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Julio. How can I help you further, Julio?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is julio'),\n",
       "  AIMessage(content='Hello Julio! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Julio. How can I help you further, Julio?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is julio\"),\n",
    "            AIMessage(content=\"Hello Julio! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ab446-7f97-4a0e-9b5a-1e7e314c2887",
   "metadata": {},
   "source": [
    "* The previous way is simple but not very practical for real agents. Let's now see how we can keep track of previous messages automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be9fdbb1-cc76-441c-9754-76a6af31b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43bf7f3a-8c02-4ab3-bdc5-5db11fe23934",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e98e6e67-16ca-403d-a79c-75f55722ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "feb7ce60-238d-4388-9872-6f9bfc95bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Julio! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm julio\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Hello Julio! How can I assist you today?'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm julio\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24b4200b-5f5e-46c8-91d5-66ae123e756e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Julio. How can I assist you today, Julio?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?'),\n",
       "  HumanMessage(content=\"hi! I'm julio\"),\n",
       "  AIMessage(content='Hello Julio! How can I assist you today?')],\n",
       " 'output': 'Your name is Julio. How can I assist you today, Julio?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d0c8f-996f-4fda-be26-addfb75a0f62",
   "metadata": {},
   "source": [
    "## Basic Agent Operations: How to Guides\n",
    "* [How to build an agent with a custom tool and memory.](https://python.langchain.com/docs/modules/agents/how_to/custom_agent/)\n",
    "* [How to add streaming.](https://python.langchain.com/docs/modules/agents/how_to/streaming/)\n",
    "* [How to return structured output.](https://python.langchain.com/docs/modules/agents/how_to/agent_structured/)\n",
    "* [How to run an agent as an iterator.](https://python.langchain.com/docs/modules/agents/how_to/agent_iter/)\n",
    "* [How to handle parsing errors.](https://python.langchain.com/docs/modules/agents/how_to/handle_parsing_errors/)\n",
    "* [How to access intermediate steps.](https://python.langchain.com/docs/modules/agents/how_to/intermediate_steps/)\n",
    "* [How to cap the max number of iterations.](https://python.langchain.com/docs/modules/agents/how_to/max_iterations/)\n",
    "* [How to add timeouts for agents.](https://python.langchain.com/docs/modules/agents/how_to/max_time_limit/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf0eb3-613d-455d-a2ec-4f0e10c2be06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
