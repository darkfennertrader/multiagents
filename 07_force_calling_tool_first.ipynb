{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f10faed-9903-428e-aa7b-cbdd94847eae",
   "metadata": {},
   "source": [
    "In this example we will build a chat executor that always calls a certain tool first. In this example, we will create an agent with a search tool. However, at the start we will force the agent to call the search tool (and then let it do whatever it wants after). This is useful when you want to force agents to call particular tools, but still want flexibility of what happens after that.\n",
    "\n",
    "This examples builds off the base chat executor. It is highly recommended you learn about that executor before going through this notebook. You can find documentation for that example here.\n",
    "\n",
    "Any modifications of that example are called below with MODIFICATION, so if you are looking for the differences you can just search for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ed06b2-2a29-418b-b2b5-e77a207f583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import OPENAI_API_KEY, TAVILY_API_KEY, LANGCHAIN_TRACING_V2, LANGCHAIN_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1433da-7298-4642-bd12-3714b0fb8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e76c0f-1bec-4da6-8bf2-053c16960a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201b4a93-1513-4354-b1c9-bf77eec04617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42a39ec-2a4f-4b72-98d1-7bbb92cbebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    messages = state[\"messages\"]\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c5b16-6493-40c4-88c9-3b2374a0cd69",
   "metadata": {},
   "source": [
    "MODIFICATION\n",
    "\n",
    "Here we create a node that returns an AIMessage with a tool call - we will use this at the start to force it call a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988520e7-39fd-4faa-9152-c8fd020286f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the new first - the first call of the model we want to explicitly hard-code some action\n",
    "from langchain_core.messages import AIMessage\n",
    "import json\n",
    "\n",
    "\n",
    "def first_model(state):\n",
    "    human_input = state[\"messages\"][-1].content\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        \"name\": \"tavily_search_results_json\",\n",
    "                        \"arguments\": json.dumps({\"query\": human_input}),\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95470e4-3515-4f57-9b8a-f92ac55b6763",
   "metadata": {},
   "source": [
    "Define the graph\n",
    "We can now put it all together and define the graph!\n",
    "\n",
    "MODIFICATION\n",
    "\n",
    "We will define a first_agent node which we will set as the entrypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ed187b-3694-4628-9b7a-84f0a8437be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the new entrypoint\n",
    "workflow.add_node(\"first_agent\", first_model)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"first_agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# After we call the first agent, we know we want to go to action\n",
    "workflow.add_edge(\"first_agent\", \"action\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113bc22f-bcd3-4245-affa-5f2dd0acfa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'first_agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"what is the weather in sf\"}'}})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [FunctionMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1713942218, \\'localtime\\': \\'2024-04-24 0:03\\'}, \\'current\\': {\\'last_updated_epoch\\': 1713942000, \\'last_updated\\': \\'2024-04-24 00:00\\', \\'temp_c\\': 14.4, \\'temp_f\\': 57.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 15.0, \\'wind_kph\\': 24.1, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1018.0, \\'pressure_in\\': 30.06, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 62, \\'cloud\\': 100, \\'feelslike_c\\': 13.5, \\'feelslike_f\\': 56.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 19.5, \\'gust_kph\\': 31.3}}\"}]', name='tavily_search_results_json')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current weather in San Francisco is as follows:\\n- Temperature: 57.9°F (14.4°C)\\n- Condition: Overcast\\n- Wind: 15.0 mph (24.1 kph) from SSW\\n- Pressure: 30.06 in\\n- Humidity: 62%\\n- Cloud Cover: 100%\\n- Visibility: 9.0 miles\\n\\nFor more details, you can visit [Weather API](https://www.weatherapi.com/).', response_metadata={'finish_reason': 'stop'}, id='run-77695cfa-58b8-4443-89f0-9bfb4bfbcac1-0')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43d159-52ec-4997-adab-d7d18c43e1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
