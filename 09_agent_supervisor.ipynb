{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7692abc-af91-46d0-a582-69c394d01298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import OPENAI_API_KEY, TAVILY_API_KEY, LANGCHAIN_TRACING_V2, LANGCHAIN_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365d54f9-da10-43af-ade5-a0cc82a05bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# This executes code locally, which can be unsafe\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea55bc46-09fd-4945-97c7-5852408002bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db85109f-7d35-44da-89a8-d6854d9b8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc783de-4bd4-4244-934e-87f7341ae986",
   "metadata": {},
   "source": [
    "Create Agent Supervisor\n",
    "It will use function calling to choose the next worker node OR finish processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e1049d-24f4-45bc-8862-a6c79f751092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Researcher\", \"Coder\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7f6d65-7ef9-474a-a552-059d164eca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "research_agent = create_agent(llm, [tavily_tool], \"You are a web researcher.\")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "code_agent = create_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    \"You may generate safe python code to analyze data and generate charts using matplotlib.\",\n",
    ")\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a064736-f761-4447-934a-1f8976ccf3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53cb3dfd-b198-4f0f-bcd9-482bc9e28c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coder': {'messages': [HumanMessage(content='The code has been executed, and \"Hello, World!\" has been printed to the terminal.', name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Code hello world and print it to the terminal\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb87dbd-9867-4ec4-ad28-2a58a897dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='Pikas are small, round, ovate-bodied mammals adapted to live in the harsh environments of mountainous areas. They belong to the genus Ochotona, the sole living genus of the family Ochotonidae. Pikas are known for their ability to thrive in cold, rocky, and treacherous habitats where other mammals rarely venture. They are particularly sensitive to high temperatures and can perish after only a few hours of exposure to temperatures around 78 degrees Fahrenheit (25.5 degrees Celsius).\\n\\nPikas do not hibernate; instead, they remain active throughout the winter, traveling in tunnels under rocks and snow, and consuming dried plants they have stored in a process known as \"haying.\" They feed year-round, but their haying activity is limited to summer months. Pikas have two foraging methods: direct consumption and gathering of plants to store for winter. They prefer foraging in temperatures below 25 degrees Celsius and may lose significant foraging time with every 1-degree Celsius increase in ambient temperature.\\n\\nThe American pika (Ochotona princeps) is one of only two pika species found in North America, with the other being the collared pika (O. collaris). The American pika inhabits the mountains of western North America, from central British Columbia and Alberta in Canada to various states in the western United States. Pikas play a crucial ecological role as \"ecosystem engineers\" by collecting and storing food in piles, thereby modifying their habitat.\\n\\nA significant threat to pikas is global climate change. Rising temperatures are forcing some populations to move to higher elevations in search of cooler habitats. Recent studies have indicated widespread extirpations and range retractions at lower elevations, which are typically warmer and drier. As early warning indicators of global warming, pikas have garnered attention for their vulnerability to climate-induced habitat changes.\\n\\nDespite the concerns, as of the information available, the American pika has not been listed under the US Endangered Species Act. However, conservation efforts continue to monitor pika populations and their responses to environmental changes.\\n\\nOverall, pikas are resilient yet delicate creatures whose existence is closely tied to the stability of their alpine ecosystems. Their survival is becoming increasingly challenging due to the effects of human-induced climate change.\\n\\nFor more detailed information and to explore further, you may visit the following sources:\\n- [Animalia](https://animalia.bio/american-pika)\\n- [National Wildlife Federation](https://www.nwf.org/Educational-Resources/Wildlife-Guide/Mammals/American-Pika)\\n- [Wikipedia (American pika)](https://en.wikipedia.org/wiki/American_pika)\\n- [Britannica](https://www.britannica.com/animal/pika)\\n- [Wikipedia (Pika)](https://en.wikipedia.org/wiki/Pika)', name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Write a brief research report on pikas.\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a3a806-307e-4980-808c-cb1c0ea7adb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='## Italian Market for Shipping - 2023 Research Report\\n\\n### Overview\\nThe Italian shipping and logistics market is experiencing various challenges and transformations in 2023. With a backdrop of economic fluctuations and market pressures, the sector is adjusting to new conditions.\\n\\n### Economic Context\\n- **GDP Growth:** The Italian economy is expected to grow by 0.7% in 2023, despite a -0.4% decrease in GDP in Q2 2023 compared to the previous quarter. Year over year, there was a 0.4% increase. The high inflation and interest rates continue to impact the economy, but some signals of improvement are on the horizon.\\n\\n### E-commerce\\n- **Market Decline:** The Italian e-commerce market saw a decline of 8.6% year-over-year in 2022, with all subsegments experiencing a downturn.\\n\\n### Exports\\n- **Food and Beverage:** Italian food and beverage exports, particularly wine, have surged in Q1 2023 with a notable 3.9% growth in wine exports.\\n\\n### Costs and Operational Challenges\\n- **Fuel and Wages:** Fuel prices and rising driver wages, due to a shortage of truck drivers, are significantly impacting the operational costs for trucking in Italy.\\n\\n### Logistics Sector\\n- **Investments and Performance:** The logistics sector has seen investments amounting to 257 million euros in Q1 2023. The market has recorded a significant take-up of 635,200 square meters, indicating robust activity.\\n- **Rental Growth:** There has been noticeable rental growth in the main markets.\\n- **Reshoring:** The pandemic and geopolitical conflicts (notably the war) have led to reshoring efforts, adjusting the dynamics of the logistics sector.\\n\\n### Infrastructure and Market Performance\\n- **Road Haulage Market:** The Italian road haulage market has outperformed the European average in recent years, even with apparent infrastructure shortcomings. The market surpassed one billion tonnes in road freight transport in 2022.\\n- **Container Shipping Rates:** In 2023, the container shipping market saw freight rates return to pre-pandemic levels on most routes.\\n\\n### Conclusion\\nThe Italian market for shipping in 2023 is navigating through economic headwinds, with growth in certain export sectors and logistical challenges due to infrastructure and labor costs. Investments in the logistics sector and adjustments to market conditions reflect resilience and an adaptive approach to ongoing global changes.', name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Write a brief research report on italian market for shipping.\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d905d8c-f38d-4ac2-a5de-e4a15837b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='Davide Malaguti is an Italian entrepreneur and business coach from Bologna. He has been teaching for over 20 years on how to maximize motivation and productivity for individuals at any level within a company. He is described as a visionary, a father, a trainer, an entrepreneur, and a life-coach. Throughout his career, more than 100,000 people have experienced the warmth, humor, and transformative power of his corporate and personal development events.\\n\\nHe has been a coach and trainer for over 25 years, currently leading seven companies, has published three books, and invented the SPEED methodology, which he has used to train and coach over 100,000 individuals. He is also recognized as an author and the creator of personal growth courses.\\n\\nFor more detailed information, you can visit his [official website](https://www.davidemalaguti.com/), check out his [LinkedIn profile](https://it.linkedin.com/in/davidemalaguti/en), or explore his content on [YouTube](https://www.youtube.com/user/GoldenGroupGG) and [Facebook](https://www.facebook.com/dottdavidemalaguti/).', name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me who is Davide Malaguti - the italian coacher born in Bologna\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be134db-d919-44f0-bb6d-35a6d00f31f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c2f5a-df7e-4be0-bca3-3d2ffec0329d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
