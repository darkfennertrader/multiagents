{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ef8013-f5a3-4bf6-9449-c7d320f3fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import OPENAI_API_KEY, TAVILY_API_KEY, LANGCHAIN_TRACING_V2, LANGCHAIN_API_KEY, ELEVEN_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15237123-3a00-4dd0-9adf-4df36a28e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated, List, Sequence, TypedDict\n",
    "from time import time\n",
    "import operator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolInvocation, ToolExecutor\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    ChatMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import END, MessageGraph, StateGraph\n",
    "from elevenlabs import play, stream, save\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb25e92-1679-4553-aa10-b46543be73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ElevenLabs()\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\", temperature=0)\n",
    "tools = [TavilySearchResults(max_results=3)]\n",
    "tool_executor = ToolExecutor(tools)\n",
    "llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1c0670-b5d4-4000-82ec-51121f1731ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(state):\n",
    "    \"\"\"\n",
    "    Use this tools to transform text to speech\n",
    "    \"\"\"\n",
    "    text = state[\"message\"][-1].content\n",
    "    audio_stream = client.generate(\n",
    "        text=text,\n",
    "        voice=\"Raimondo Marino\",  # \"Davide\"\n",
    "        model=\"eleven_multilingual_v2\",\n",
    "        stream=True,\n",
    "    )\n",
    "    return stream(audio_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bcbf92-1316-4880-80a8-5c241c9cb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # sender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d9b740-a51b-4855-8ebe-99fe97894c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a850cf-1faa-4d26-8aaf-deff8bc53e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4a0de9-16ad-4a02-8858-1bb5b7a31c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(state):\n",
    "    messages = state[\"messages\"]\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6ab1de-5fa1-4b80-bf0f-5ecedd3db2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_agent(state):\n",
    "    human_input = state[\"messages\"][-1].content\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"text_to_speech\",\n",
    "                        \"args\": {\n",
    "                            \"text\": human_input,\n",
    "                        },\n",
    "                        \"id\": \"tool_abcd123\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ebdb90-58d5-4076-a860-46b54bff828f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Node `agent` is a dead-end",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_edge(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_tool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m builder\u001b[38;5;241m.\u001b[39mset_finish_point(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_to_speech\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langgraph/graph/state.py:85\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m     82\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m     88\u001b[0m state_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langgraph/graph/graph.py:205\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_starts:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is a dead-end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    207\u001b[0m all_branches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    208\u001b[0m     branch\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m branches \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranches\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m branch \u001b[38;5;129;01min\u001b[39;00m branches\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    211\u001b[0m ]\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(branch\u001b[38;5;241m.\u001b[39mends \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m branch \u001b[38;5;129;01min\u001b[39;00m all_branches):\n",
      "\u001b[0;31mValueError\u001b[0m: Node `agent` is a dead-end"
     ]
    }
   ],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(key=\"agent\", action=call_model)\n",
    "builder.add_node(key=\"call_tool\", action=call_tool)\n",
    "builder.add_node(key=\"text_to_speech\", action=text_to_speech)\n",
    "builder.set_entry_point(\"agent\")\n",
    "builder.add_conditional_edges(\n",
    "    start_key=\"call_tool\",\n",
    "    condition=should_continue,\n",
    "    conditional_edge_mapping={\n",
    "        \"continue\": \"call_tool\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "builder.add_edge(\"call_tool\", \"agent\")\n",
    "builder.set_finish_point(\"text_to_speech\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126141f-c315-46f6-b069-5cd15e7a2a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
